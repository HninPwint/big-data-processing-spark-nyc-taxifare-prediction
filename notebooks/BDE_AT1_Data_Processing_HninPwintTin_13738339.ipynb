{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import StringType \n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import TimestampType \n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start the Spark Session\n",
    "# spark = SparkSession.builder.appName('new_york_taxi_fare_prediction').getOrCreate()\n",
    "\n",
    "cpu_num = multiprocessing.cpu_count()\n",
    "pool_num = cpu_num - 1\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName('new_york_taxi_fare_prediction')\\\n",
    "        .master('local[' + str(pool_num) + ']')\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.csv(\"../data/raw/yellow_tripdata_20*.csv\", header=True)\n",
    "df_green = spark.read.csv(\"../data/raw/green_tripdata_20*.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning and Merging\n",
    "1. Add one new column to differentiate the two Taxi Campany - \"taxi_campany\": Green/Yellow\n",
    "2. the numbe of Columns are diffrent in the dataset of two Taxi Campanies. So drop the uncommon two columns\n",
    "3. Rename the column names \"lpep_pickup_datetime\" and \"tpep_pickup_datetime\" to \"pickup_datetime\" to achieve the uniformity\n",
    "4. Rename the column names \"lpep_dropoff_datetime\" and \"tpep_dropoff_datetime\" to \"dropoff_datetime\" to achieve the uniformity\n",
    "5. Concantane the dataframes\n",
    "6. Extract the years/day/hour from the pick-up time\n",
    "7. Filter out the data only for 2017 and 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Add new column to diffientiate the Taxi campany\n",
    "df_yellow = df_yellow.withColumn('taxi_campany', F.lit(\"Green\"))\n",
    "df_green = df_green.withColumn('taxi_campany', F.lit(\"Yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the uncommon column\n",
    "df_green = df_green.drop(\"ehail_fee\", \"trip_type\")\n",
    "\n",
    "# Rename the columns tpep_pickup_datetime to pickup_datetime / tpep_dropoff_datetime to dropoff_datetime\n",
    "df_yellow = df_yellow.withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\")\n",
    "df_yellow = df_yellow.withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "# Make the column names lowercase\n",
    "for col in df_yellow.columns:\n",
    "    df_yellow = df_yellow.withColumnRenamed(col, col.lower())\n",
    "    \n",
    "# Rename the columns lpep_pickup_datetime to pickup_datetime / lpep_dropoff_datetime to dropoff_datetime\n",
    "df_green = df_green.withColumnRenamed(\"lpep_pickup_datetime\", \"pickup_datetime\")\n",
    "df_green = df_green.withColumnRenamed(\"lpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "for col in df_green.columns:\n",
    "    df_green = df_green.withColumnRenamed(col, col.lower())\n",
    "\n",
    "df = df_green.unionByName(df_yellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Merged Dataset in Parquet Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format('parquet').save(\"../data/processed/df_original_final.parquet\", mode='append')\n",
    "# spark.stop()\n",
    "##### Started saving at 10:36 PM on 12 April, finished at 10:54\n",
    "### 5:13 - 5: 29 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Saved Raw Data in Parquet Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start loading the parquet file.\n",
    "df_original = spark.read.parquet(\"../data/processed/df_original_final.parquet\")\n",
    "### start reading at 11:37AM - finished within 2 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|       2|2018-11-22 22:37:46|2018-11-22 22:43:06|                 N|         1|          43|         237|              2|         1.26|        6.5|  0.5|    0.5|         0|           0|                  0.3|         7.8|           2|       Green|\n",
      "|       2|2018-11-22 22:51:04|2018-11-22 23:44:18|                 N|         1|         236|         262|              3|        21.71|       62.5|  0.5|    0.5|        10|           0|                  0.3|        73.8|           1|       Green|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_original.show(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run Step 1 to 3 in three batches as show below and save into in Parquet Format\n",
    "Primary Year filtering - to avoid the invalid years - 2032, 2029, 2053 etc\n",
    "Setting lower and upper bound of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Batch 1 ########\n",
    "df_cleaned_2017 = df_original.filter((F.year(F.col('pickup_datetime')) == 2017))\n",
    "df_cleaned_2017 = df_cleaned_2017.filter(\n",
    "                    (((F.col('trip_distance'))>0) & ((F.col('trip_distance'))<100)) &\n",
    "                    ((F.col('mta_tax'))>=0) &\n",
    "                    (((F.col('fare_amount'))>0) & ((F.col('fare_amount'))<200)) &\n",
    "                    (((F.col('total_amount'))>0) & ( (F.col('total_amount'))<200)) &\n",
    "                    (((F.col('passenger_count'))>0) & ((F.col('passenger_count'))<10)))\n",
    "df_cleaned_2017.write.format('parquet').save('../data/processed/df_original_cleaned_years_dataranges_final.parquet', mode='append')\n",
    "\n",
    "\n",
    "######### Batch 2 ########\n",
    "df_cleaned_2018_green = df_original.filter((F.year(F.col('pickup_datetime')) == 2018) & (F.col('taxi_campany') == 'Green'))\n",
    "df_cleaned_2018_green = df_cleaned_2018_green.filter(\n",
    "                    (((F.col('trip_distance'))>0) & ((F.col('trip_distance'))<100)) &\n",
    "                    ((F.col('mta_tax'))>=0) &\n",
    "                    (((F.col('fare_amount'))>0) & ((F.col('fare_amount'))<200)) &\n",
    "                    (((F.col('total_amount'))>0) & ( (F.col('total_amount'))<200)) &\n",
    "                    (((F.col('passenger_count'))>0) & ((F.col('passenger_count'))<10)))\n",
    "df_cleaned_2018_green.write.format('parquet').save('../data/processed/df_original_cleaned_years_dataranges_final.parquet', mode='append')\n",
    "\n",
    "\n",
    "######### Batch 3 ########\n",
    "df_cleaned_2018_yellow = df_original.filter((F.year(F.col('pickup_datetime')) == 2018) & (F.col('taxi_campany') == 'Yellow'))\n",
    "df_cleaned_2018_yellow = df_cleaned_2018_yellow.filter(\n",
    "                    (((F.col('trip_distance'))>0) & ((F.col('trip_distance'))<100)) &\n",
    "                    ((F.col('mta_tax'))>=0) &\n",
    "                    (((F.col('fare_amount'))>0) & ((F.col('fare_amount'))<200)) &\n",
    "                    (((F.col('total_amount'))>0) & ( (F.col('total_amount'))<200)) &\n",
    "                    (((F.col('passenger_count'))>0) & ((F.col('passenger_count'))<10)))\n",
    "df_cleaned_2018_yellow.write.format('parquet').save('../data/processed/df_original_cleaned_years_dataranges_final.parquet', mode='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|       2|2018-06-01 00:33:55|2018-06-01 00:36:13|                 N|         1|          66|          33|              5|          .51|          4|  0.5|    0.5|       0.7|           0|                  0.3|           6|           1|      Yellow|\n",
      "|       2|2018-06-01 00:40:36|2018-06-01 00:49:46|                 N|         1|          25|          49|              5|         1.97|          9|  0.5|    0.5|      2.06|           0|                  0.3|       12.36|           1|      Yellow|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_2018_yellow.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The last batch of filter \n",
    "df_cleaned_2018_yellow = df_cleaned_2018_yellow.filter(\n",
    "                    (((F.col('trip_distance'))>0) & ((F.col('trip_distance'))<100)) &\n",
    "                    ((F.col('mta_tax'))>=0) &\n",
    "                    (((F.col('fare_amount'))>0) & ((F.col('fare_amount'))<200)) &\n",
    "                    (((F.col('total_amount'))>0) & ( (F.col('total_amount'))<200)) &\n",
    "                    (((F.col('passenger_count'))>0) & ((F.col('passenger_count'))<10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|       2|2018-06-01 00:40:36|2018-06-01 00:49:46|                 N|         1|          25|          49|              5|         1.97|          9|  0.5|    0.5|      2.06|           0|                  0.3|       12.36|           1|      Yellow|\n",
      "|       2|2018-06-01 00:57:12|2018-06-01 01:02:58|                 N|         1|          61|          49|              5|         1.40|        6.5|  0.5|    0.5|         0|           0|                  0.3|         7.8|           2|      Yellow|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_2018_yellow.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Cleaned Raw Dataset saved in Parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in three batch due to Mem GC error\n",
    "df_cleaned_2018_yellow.write.format('parquet').save('../data/processed/df_original_cleaned_years_dataranges_final.parquet', mode='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Saved Data - which is filter out the invalid years and data ranges\n",
    "\n",
    "The aim in this step is to convert the data types and add new features -\n",
    "1) weekday\n",
    "2) pick-up hour\n",
    "3) trip duration in seconed\n",
    "4) trip duration ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load again here - \"df_original_cleaned_years_and_ranges\" next step\n",
    "df_cleaned_2year = spark.read.parquet(\"../data/processed/df_original_cleaned_years_dataranges_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_2year.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour and weekday from pickup time column\n",
    "df_cleaned_transformed_1 = df_cleaned_2year.withColumn('pickup_hour', F.hour(F.col('pickup_datetime'))).\\\n",
    "            withColumn('week_day_num', F.date_format(F.col('pickup_datetime'), 'u')).\\\n",
    "            withColumn('week_day_abb', F.date_format(F.col('pickup_datetime'), 'E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+\n",
      "|       2|2018-09-12 20:35:43|2018-09-12 21:20:48|                 N|         1|         237|          13|              1|         6.10|       28.5|  0.5|    0.5|         5|           0|                  0.3|        34.8|           1|       Green|         20|           3|         Wed|\n",
      "|       1|2018-09-12 20:32:15|2018-09-12 20:42:39|                 N|         1|         238|         142|              2|         1.70|          9|  0.5|    0.5|         1|           0|                  0.3|        11.3|           1|       Green|         20|           3|         Wed|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_transformed_1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the Data Types to Numerical \n",
    "df_cleaned_transformed_2 = df_cleaned_transformed_1.withColumn('passenger_count', F.col('passenger_count').astype(IntegerType())).\\\n",
    "              withColumn('week_day_num', F.col('week_day_num').astype(IntegerType())).\\\n",
    "              withColumn('trip_distance', F.col('trip_distance').astype(FloatType())).\\\n",
    "              withColumn('total_amount', F.col('total_amount').astype(FloatType())).\\\n",
    "              withColumn('tolls_amount', F.col('tolls_amount').astype(FloatType())).\\\n",
    "              withColumn('fare_amount', F.col('fare_amount').astype(FloatType())).\\\n",
    "              withColumn('mta_tax', F.col('mta_tax').astype(FloatType()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_cleaned_transformed_2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF for Trip Duration\n",
    "def time_delta(y,x): \n",
    "    from datetime import datetime\n",
    "    end = datetime.strptime(y, '%Y-%m-%d %H:%M:%S')\n",
    "    start = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    timedelta = int((end-start).total_seconds())\n",
    "    return timedelta\n",
    "    \n",
    "\n",
    "from pyspark.sql.functions import struct\n",
    "udf_calcluate_duration = F.udf(lambda x: time_delta(x[1],x[0]), IntegerType())\n",
    "\n",
    "df_cleaned_transformed_3 = df_cleaned_transformed_2.withColumn('trip_duration_sec', udf_calcluate_duration(struct('pickup_datetime', 'dropoff_datetime')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|trip_duration_sec|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+\n",
      "|       2|2018-09-12 20:35:43|2018-09-12 21:20:48|                 N|         1|         237|          13|              1|          6.1|       28.5|  0.5|    0.5|         5|         0.0|                  0.3|        34.8|           1|       Green|         20|           3|         Wed|             2705|\n",
      "|       1|2018-09-12 20:32:15|2018-09-12 20:42:39|                 N|         1|         238|         142|              2|          1.7|        9.0|  0.5|    0.5|         1|         0.0|                  0.3|        11.3|           1|       Green|         20|           3|         Wed|              624|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_transformed_3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF for Speed Km-per-hour\n",
    "def cal_speed(dist, duration): \n",
    "    duration = duration/3600\n",
    "    if(duration <= 0):\n",
    "       return 0\n",
    "    # Convert Mile to Km\n",
    "    dist = dist/0.621371\n",
    "    \n",
    "    speed = round(dist/duration, 2)\n",
    "    return speed\n",
    "    \n",
    "from pyspark.sql.functions import struct\n",
    "udf_calcluate_speed = F.udf(lambda x: cal_speed(x[0],x[1]), FloatType())\n",
    "\n",
    "df_cleaned_transformed_4 = df_cleaned_transformed_3.withColumn('speed_km_hr', udf_calcluate_speed(struct('trip_distance', 'trip_duration_sec')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|trip_duration_sec|speed_km_hr|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+\n",
      "|       2|2018-09-12 20:35:43|2018-09-12 21:20:48|                 N|         1|         237|          13|              1|          6.1|       28.5|  0.5|    0.5|         5|         0.0|                  0.3|        34.8|           1|       Green|         20|           3|         Wed|             2705|      13.07|\n",
      "|       1|2018-09-12 20:32:15|2018-09-12 20:42:39|                 N|         1|         238|         142|              2|          1.7|        9.0|  0.5|    0.5|         1|         0.0|                  0.3|        11.3|           1|       Green|         20|           3|         Wed|              624|      15.78|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_transformed_4.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UDF for binning Trip during into <5, 5-10, 10-20, 20-30, >30 in minutes\n",
    "## The func takes the pre-calculated trip duration in minutes\n",
    "def bin_trip_duration_min(x): \n",
    "    timedelta = x/60   \n",
    "    if(timedelta < 5):\n",
    "        range_string = \"<5 mins\"\n",
    "    elif( (timedelta >= 5) & (timedelta <10)):\n",
    "        range_string = \"5-10 mins\"\n",
    "    elif( (timedelta >= 10) & (timedelta <20)):\n",
    "        range_string = \"10-20 mins\"\n",
    "    elif( (timedelta >= 20) & (timedelta <30)):\n",
    "        range_string = \"20-30 mins\"\n",
    "    else: range_string = \">30 mins\"       \n",
    "    return range_string\n",
    "\n",
    "udf_bin_trip_duration_min = F.udf(lambda x: bin_trip_duration_min(x), StringType())\n",
    "df_cleaned_transformed_5 = df_cleaned_transformed_4.withColumn('trip_duration_range_mins', udf_bin_trip_duration_min(F.col(\"trip_duration_sec\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|trip_duration_sec|speed_km_hr|trip_duration_range_mins|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "|       2|2018-09-12 20:35:43|2018-09-12 21:20:48|                 N|         1|         237|          13|              1|          6.1|       28.5|  0.5|    0.5|         5|         0.0|                  0.3|        34.8|           1|       Green|         20|           3|         Wed|             2705|      13.07|                >30 mins|\n",
      "|       1|2018-09-12 20:32:15|2018-09-12 20:42:39|                 N|         1|         238|         142|              2|          1.7|        9.0|  0.5|    0.5|         1|         0.0|                  0.3|        11.3|           1|       Green|         20|           3|         Wed|              624|      15.78|              10-20 mins|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_transformed_5.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_transformed_6 = df_cleaned_transformed_5.filter(\n",
    "                    (((F.col('speed_km_hr'))>0) & ((F.col('speed_km_hr'))< 100))  &     \n",
    "                    (((F.col('trip_duration_sec'))>0) & ((F.col('trip_duration_sec')) < 2000)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|trip_duration_sec|speed_km_hr|trip_duration_range_mins|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "|       1|2018-09-12 20:32:15|2018-09-12 20:42:39|                 N|         1|         238|         142|              2|          1.7|        9.0|  0.5|    0.5|         1|         0.0|                  0.3|        11.3|           1|       Green|         20|           3|         Wed|              624|      15.78|              10-20 mins|\n",
      "|       2|2018-09-12 20:04:02|2018-09-12 20:11:26|                 N|         1|         237|         140|              1|         1.07|        6.5|  0.5|    0.5|      1.56|         0.0|                  0.3|        9.36|           1|       Green|         20|           3|         Wed|              444|      13.96|               5-10 mins|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_transformed_6.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the cleaned version of all year with col + new column\n",
    "df_cleaned_transformed_6.write.format('parquet').save('../data/processed/df_transformed_2yr.parquet', mode='append')\n",
    "#6:12 am - failed at 6:35  \n",
    "# 2:25 - 10: 19PM , completed with Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the saved Cleaned data with alll columns to do next step - filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_super = spark.read.parquet(\"../data/processed/df_transformed_2yr_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|trip_duration_sec|speed_km_hr|trip_duration_range_mins|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "|       2|2017-09-16 15:36:34|2017-09-16 15:43:43|                 N|         1|         234|         164|              1|         1.15|        6.5|    0|    0.5|      1.46|         0.0|                  0.3|        8.76|           1|       Green|         15|           6|         Sat|              429|      15.53|               5-10 mins|\n",
      "|       1|2017-09-16 15:04:59|2017-09-16 15:33:25|                 N|         1|         233|         239|              1|          4.0|       21.0|    0|    0.5|         0|         0.0|                  0.3|        21.8|           2|       Green|         15|           6|         Sat|             1706|      13.58|              20-30 mins|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### This cleaned dataset is ready to use for SQL Business Queries from here\n",
    "df_cleaned_super.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Year and month for extraction in later step\n",
    "df_cleaned_super = df_cleaned_super.withColumn('year', F.year(F.col('pickup_datetime'))).\\\n",
    "                                    withColumn('month', F.month(F.col('pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+----+-----+\n",
      "|vendorid|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|ratecodeid|pulocationid|dolocationid|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_campany|pickup_hour|week_day_num|week_day_abb|trip_duration_sec|speed_km_hr|trip_duration_range_mins|year|month|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+----+-----+\n",
      "|       2|2017-09-16 15:36:34|2017-09-16 15:43:43|                 N|         1|         234|         164|              1|         1.15|        6.5|    0|    0.5|      1.46|         0.0|                  0.3|        8.76|           1|       Green|         15|           6|         Sat|              429|      15.53|               5-10 mins|2017|    9|\n",
      "|       1|2017-09-16 15:04:59|2017-09-16 15:33:25|                 N|         1|         233|         239|              1|          4.0|       21.0|    0|    0.5|         0|         0.0|                  0.3|        21.8|           2|       Green|         15|           6|         Sat|             1706|      13.58|              20-30 mins|2017|    9|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+-----------+------------+------------+-----------------+-----------+------------------------+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_super.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features interested: for Modelling\n",
    "cols_list = ['year', 'month','passenger_count','store_and_fwd_flag', 'pulocationid', 'trip_distance', 'trip_duration_sec', 'total_amount', 'pickup_hour',\n",
    "             'ratecodeid', 'tolls_amount', 'taxi_campany','week_day_abb','week_day_num', 'trip_duration_range_mins', 'speed_km_hr']\n",
    "\n",
    "# Subset the columns\n",
    "df_super_cleaned_model = df_cleaned_super.select(cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+\n",
      "|year|month|passenger_count|store_and_fwd_flag|pulocationid|trip_distance|trip_duration_sec|total_amount|pickup_hour|ratecodeid|tolls_amount|taxi_campany|week_day_abb|week_day_num|trip_duration_range_mins|speed_km_hr|\n",
      "+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+\n",
      "|2017|    9|              1|                 N|         234|         1.15|              429|        8.76|         15|         1|         0.0|       Green|         Sat|           6|               5-10 mins|      15.53|\n",
      "|2017|    9|              1|                 N|         233|          4.0|             1706|        21.8|         15|         1|         0.0|       Green|         Sat|           6|              20-30 mins|      13.58|\n",
      "|2017|    9|              1|                 N|         230|         6.83|             1585|       27.88|         15|         1|         0.0|       Green|         Sat|           6|              20-30 mins|      24.97|\n",
      "|2017|    9|              1|                 N|         234|         1.76|             1243|       17.76|         15|         1|         0.0|       Green|         Sat|           6|              20-30 mins|        8.2|\n",
      "|2017|    9|              1|                 N|          79|         1.92|             1073|       15.96|         15|         1|         0.0|       Green|         Sat|           6|              10-20 mins|      10.37|\n",
      "+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_super_cleaned_model.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Building Performed in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoderEstimator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stages = []\n",
    "\n",
    "# Categorical Variable Encoding\n",
    "cat_cols = ['ratecodeid', 'taxi_campany', 'trip_duration_range_mins', 'store_and_fwd_flag', 'pulocationid', 'week_day_num']\n",
    "for cat_col in cat_cols:\n",
    "    col_indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_ind\")\n",
    "    col_encoder = OneHotEncoderEstimator(inputCols=[f\"{cat_col}_ind\"], outputCols=[f\"{cat_col}_ohe\"])\n",
    "    stages += [col_indexer, col_encoder]\n",
    "    \n",
    "cat_cols_ohe = [f\"{cat_col}_ohe\" for cat_col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Variables in the model\n",
    "num_cols = ['passenger_count', 'trip_distance', 'pickup_hour', 'total_amount', 'year', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorise the encoded categorical columns and numeric columns to inform the pipeline\n",
    "assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol=\"features\")\n",
    "assembler.setHandleInvalid(\"keep\")\n",
    "\n",
    "stages += [assembler]\n",
    "\n",
    "## Construct the pipeline\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supply the Data to pipeline\n",
    "pipeline_model = pipeline.fit(df_super_cleaned_model)\n",
    "### 6:25 - 6:28, 6:37 - 6:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trigger transformation pipeline wtih  3-months of data \n",
    "pipelined_super_cleaned_2yr_df = pipeline_model.transform(df_super_cleaned_model)\n",
    "#7:17 - 7:18 ## 7:32 - 7:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+--------------+--------------+----------------+----------------+----------------------------+----------------------------+----------------------+----------------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "|year|month|passenger_count|store_and_fwd_flag|pulocationid|trip_distance|trip_duration_sec|total_amount|pickup_hour|ratecodeid|tolls_amount|taxi_campany|week_day_abb|week_day_num|trip_duration_range_mins|speed_km_hr|ratecodeid_ind|ratecodeid_ohe|taxi_campany_ind|taxi_campany_ohe|trip_duration_range_mins_ind|trip_duration_range_mins_ohe|store_and_fwd_flag_ind|store_and_fwd_flag_ohe|pulocationid_ind|pulocationid_ohe|week_day_num_ind|week_day_num_ohe|            features|\n",
      "+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+--------------+--------------+----------------+----------------+----------------------------+----------------------------+----------------------+----------------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "|2017|    9|              1|                 N|         234|         1.15|              429|        8.76|         15|         1|         0.0|       Green|         Sat|           6|               5-10 mins|      15.53|           0.0| (6,[0],[1.0])|             0.0|   (1,[0],[1.0])|                         1.0|               (4,[1],[1.0])|                   0.0|         (1,[0],[1.0])|             6.0| (264,[6],[1.0])|             0.0|   (6,[0],[1.0])|(288,[0,6,8,11,18...|\n",
      "|2017|    9|              1|                 N|         233|          4.0|             1706|        21.8|         15|         1|         0.0|       Green|         Sat|           6|              20-30 mins|      13.58|           0.0| (6,[0],[1.0])|             0.0|   (1,[0],[1.0])|                         2.0|               (4,[2],[1.0])|                   0.0|         (1,[0],[1.0])|            35.0|(264,[35],[1.0])|             0.0|   (6,[0],[1.0])|(288,[0,6,9,11,47...|\n",
      "+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+--------------+--------------+----------------+----------------+----------------------------+----------------------------+----------------------+----------------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelined_super_cleaned_2yr_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the Data ready in the format of the vectorised features plus  original feature\n",
    "pipelined_cleaned_2yr_final_df = pipelined_super_cleaned_2yr_df.select(['features'] + cols_list)\n",
    "#6:31 - 6:31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+\n",
      "|            features|year|month|passenger_count|store_and_fwd_flag|pulocationid|trip_distance|trip_duration_sec|total_amount|pickup_hour|ratecodeid|tolls_amount|taxi_campany|week_day_abb|week_day_num|trip_duration_range_mins|speed_km_hr|\n",
      "+--------------------+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+\n",
      "|(288,[0,6,8,11,18...|2017|    9|              1|                 N|         234|         1.15|              429|        8.76|         15|         1|         0.0|       Green|         Sat|           6|               5-10 mins|      15.53|\n",
      "|(288,[0,6,9,11,47...|2017|    9|              1|                 N|         233|          4.0|             1706|        21.8|         15|         1|         0.0|       Green|         Sat|           6|              20-30 mins|      13.58|\n",
      "+--------------------+----+-----+---------------+------------------+------------+-------------+-----------------+------------+-----------+----------+------------+------------+------------+------------+------------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### See the pipeline data output\n",
    "pipelined_cleaned_2yr_final_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data Performed in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data of last three months for testing\n",
    "\n",
    "test_data = pipelined_cleaned_2yr_final_df.filter((F.col('year') == 2018) & (((F.col('month') == 10) |(F.col('month') == 11) |(F.col('month') == 12)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data of first 21 months for testing\n",
    "train_data = pipelined_cleaned_2yr_final_df.filter(((F.col('year') == 2017) & ((F.col('month') >= 1) & (F.col('month') <= 12)))|\n",
    "                                                 ((F.col('year') == 2018) & ((F.col('month') >= 1) & (F.col('month') <= 9))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+------------+-----------+------------+----------+------------+------------+------------------------+------------------+------------+\n",
      "|            features|passenger_count|trip_distance|total_amount|pickup_hour|week_day_num|ratecodeid|pulocationid|taxi_campany|trip_duration_range_mins|store_and_fwd_flag|tolls_amount|\n",
      "+--------------------+---------------+-------------+------------+-----------+------------+----------+------------+------------+------------------------+------------------+------------+\n",
      "|(284,[0,6,7,11,12...|              1|         0.46|        10.3|         17|           5|         1|         237|       Green|              10-20 mins|                 N|         0.0|\n",
      "|(284,[0,6,7,11,12...|              1|          0.5|         8.3|         11|           5|         1|         237|       Green|              10-20 mins|                 N|         0.0|\n",
      "+--------------------+---------------+-------------+------------+-----------+------------+----------+------------+------------+------------------------+------------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Done in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='total_amount', maxIter = 10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training Done on  Google Colab\n",
    "lr_model = lr.fit(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_new = lr_model.summary\n",
    "summ_new.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(train_data)\n",
    "lr_predictions.select(\"prediction\",\"total_amount\",\"features\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"total_amount\", metricName=\"rmse\")\n",
    "rmse = lr_evaluator.evaluate(lr_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on Train data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions_test = lr_model.transform(test_data)\n",
    "lr_predictions_test.select(\"prediction\",\"total_amount\",\"features\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL - Python - Business Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_super = spark.read.parquet(\"../data/processed/df_transformed_2yr_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_super.createOrReplaceTempView(\"nyc_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------+\n",
      "|year|month|number_of_trips|\n",
      "+----+-----+---------------+\n",
      "|2017|    1|       10780387|\n",
      "|2017|    2|       10192088|\n",
      "|2017|    3|       11453266|\n",
      "|2017|    4|       11127959|\n",
      "|2017|    5|       11161587|\n",
      "|2017|    6|       10633460|\n",
      "|2017|    7|        9503269|\n",
      "|2017|    8|        9289554|\n",
      "|2017|    9|        9827956|\n",
      "|2017|   10|       10694462|\n",
      "|2017|   11|       10158994|\n",
      "|2017|   12|       10414465|\n",
      "|2018|    1|        9553631|\n",
      "|2018|    2|        9262273|\n",
      "|2018|    3|       10266415|\n",
      "|2018|    4|       10105415|\n",
      "|2018|    5|       10021377|\n",
      "|2018|    6|        9453060|\n",
      "|2018|    7|        8534027|\n",
      "|2018|    8|        8515365|\n",
      "+----+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.a.i - What is the total number of trip for each month\n",
    "spark.sql('''\n",
    "SELECT YEAR(pickup_datetime) year,\n",
    "       MONTH(pickup_datetime) month,\n",
    "       COUNT (1) number_of_trips\n",
    "FROM nyc_view\n",
    "GROUP BY YEAR(pickup_datetime), MONTH(pickup_datetime)\n",
    "ORDER BY 1,2\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+---------------+----+\n",
      "|year|month|weekday|number_of_trips|rank|\n",
      "+----+-----+-------+---------------+----+\n",
      "|2017|    1|    Wed|        1385000|   7|\n",
      "|2017|    2|    Mon|        1304355|   7|\n",
      "|2017|    3|    Tue|        1176901|   7|\n",
      "|2017|    4|    Mon|        1300638|   7|\n",
      "|2017|    5|    Sun|        1317906|   7|\n",
      "|2017|    6|    Sun|        1234313|   7|\n",
      "|2017|    7|    Tue|        1188752|   7|\n",
      "|2017|    8|    Sun|        1058619|   7|\n",
      "|2017|    9|    Mon|        1149302|   7|\n",
      "|2017|   10|    Wed|        1406840|   7|\n",
      "|2017|   11|    Sun|        1253896|   7|\n",
      "|2017|   12|    Mon|        1159131|   7|\n",
      "|2018|    1|    Sun|        1136214|   7|\n",
      "|2018|    2|    Sun|        1148060|   7|\n",
      "|2018|    3|    Wed|        1151506|   7|\n",
      "|2018|    4|    Tue|        1346255|   7|\n",
      "|2018|    5|    Sun|        1125833|   7|\n",
      "|2018|    6|    Sun|        1099915|   7|\n",
      "|2018|    7|    Sat|        1076810|   7|\n",
      "|2018|    8|    Sun|         936170|   7|\n",
      "+----+-----+-------+---------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.a.ii - Which weekday had the most trip\n",
    "spark.sql('''\n",
    "WITH trip_rank AS(\n",
    "SELECT *,\n",
    "        RANK() OVER(PARTITION BY year,month ORDER BY number_of_trips DESC) rank\n",
    "FROM (\n",
    "        SELECT \n",
    "            YEAR(pickup_datetime) year, \n",
    "            MONTH(pickup_datetime) month,\n",
    "            week_day_abb weekday,\n",
    "            Count(*)  number_of_trips\n",
    "\n",
    "        FROM nyc_view\n",
    "        GROUP BY YEAR(pickup_datetime), MONTH(pickup_datetime), week_day_abb      \n",
    "        ORDER BY 1,2,3\n",
    ")\n",
    ")\n",
    "SELECT * FROM trip_rank\n",
    "WHERE rank = 7\n",
    "ORDER BY year,month\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---------------------+----+\n",
      "|year|month|hour|total_number_of_trips|rank|\n",
      "+----+-----+----+---------------------+----+\n",
      "|2017|    1|  18|               692726|   1|\n",
      "|2017|    2|  18|               673287|   1|\n",
      "|2017|    3|  19|               735218|   1|\n",
      "|2017|    4|  18|               697420|   1|\n",
      "|2017|    5|  18|               690046|   1|\n",
      "|2017|    6|  18|               656818|   1|\n",
      "|2017|    7|  18|               589087|   1|\n",
      "|2017|    8|  18|               588260|   1|\n",
      "|2017|    9|  19|               622207|   1|\n",
      "|2017|   10|  18|               684103|   1|\n",
      "|2017|   11|  18|               650704|   1|\n",
      "|2017|   12|  18|               647202|   1|\n",
      "|2018|    1|  18|               632957|   1|\n",
      "|2018|    2|  18|               614335|   1|\n",
      "|2018|    3|  18|               667507|   1|\n",
      "|2018|    4|  18|               661268|   1|\n",
      "|2018|    5|  18|               636948|   1|\n",
      "|2018|    6|  18|               591743|   1|\n",
      "|2018|    7|  18|               547694|   1|\n",
      "|2018|    8|  18|               553496|   1|\n",
      "+----+-----+----+---------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.a.iii Which hour of the day had the most trip\n",
    "spark.sql('''\n",
    "WITH trip_rank AS(\n",
    "SELECT *,\n",
    "        RANK() OVER(PARTITION BY year,month ORDER BY total_number_of_trips DESC) rank\n",
    "FROM (\n",
    "        SELECT \n",
    "            YEAR(pickup_datetime) year, \n",
    "            MONTH(pickup_datetime) month,\n",
    "            Hour(pickup_datetime) hour,\n",
    "            Count(*) total_number_of_trips\n",
    "\n",
    "        FROM nyc_view\n",
    "        GROUP BY YEAR(pickup_datetime), MONTH(pickup_datetime), hour(pickup_datetime)  \n",
    "        ORDER BY 1,2,3\n",
    ")\n",
    ")\n",
    "SELECT * FROM trip_rank\n",
    "WHERE rank = 1\n",
    "ORDER BY year,month\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------------+----------------+-------------------+\n",
      "|year|month|total_passenger_count|total_trip_count|avg_passenger_count|\n",
      "+----+-----+---------------------+----------------+-------------------+\n",
      "|2017|    1|             11977257|         7454214|                  1|\n",
      "|2017|    2|             11373058|         7095996|                  1|\n",
      "|2017|    3|             12262729|         7692202|                  1|\n",
      "|2017|    4|             12287367|         7659237|                  1|\n",
      "|2017|    5|             12054726|         7545181|                  1|\n",
      "|2017|    6|             11595562|         7239610|                  1|\n",
      "|2017|    7|             10668300|         6591228|                  1|\n",
      "|2017|    8|             10402774|         6453155|                  1|\n",
      "|2017|    9|             10743991|         6676683|                  1|\n",
      "|2017|   10|             11644272|         7258643|                  1|\n",
      "|2017|   11|             10875274|         6790598|                  1|\n",
      "|2017|   12|             11217601|         6916721|                  1|\n",
      "|2018|    1|             12582854|         8107463|                  1|\n",
      "|2018|    2|             12208190|         7912285|                  1|\n",
      "|2018|    3|             13334384|         8607307|                  1|\n",
      "|2018|    4|             13105392|         8447906|                  1|\n",
      "|2018|    5|             12910119|         8338469|                  1|\n",
      "|2018|    6|             12249109|         7907786|                  1|\n",
      "|2018|    7|             12924577|         8272445|                  1|\n",
      "|2018|    8|             11135215|         7180931|                  1|\n",
      "+----+-----+---------------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.a.iv What was the average number of passenger?\n",
    "### Avg passenger = total Passenger / total number of Trip\n",
    "spark.sql('''\n",
    "SELECT \n",
    "    YEAR(pickup_datetime) year, \n",
    "    MONTH(pickup_datetime) month,\n",
    "    SUM(passenger_count) total_passenger_count,\n",
    "    COUNT(*) total_trip_count,\n",
    "    FLOOR((SUM(passenger_count)/COUNT(*))) avg_passenger_count\n",
    "FROM nyc_view\n",
    "GROUP BY YEAR(pickup_datetime), MONTH(pickup_datetime)\n",
    "ORDER By 1,2\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------------+\n",
      "|year|month|avg_amount_per_trip|\n",
      "+----+-----+-------------------+\n",
      "|2017|    1|              15.71|\n",
      "|2017|    2|              15.74|\n",
      "|2017|    3|              15.87|\n",
      "|2017|    4|              15.83|\n",
      "|2017|    5|              15.82|\n",
      "|2017|    6|              15.73|\n",
      "|2017|    7|              15.97|\n",
      "|2017|    8|              15.95|\n",
      "|2017|    9|              15.95|\n",
      "|2017|   10|              15.96|\n",
      "|2017|   11|              15.91|\n",
      "|2017|   12|              15.86|\n",
      "|2018|    1|               15.6|\n",
      "|2018|    2|               15.6|\n",
      "|2018|    3|              15.59|\n",
      "|2018|    4|              15.79|\n",
      "|2018|    5|              15.88|\n",
      "|2018|    6|              15.82|\n",
      "|2018|    7|              15.92|\n",
      "|2018|    8|              15.94|\n",
      "+----+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.a.v What was the average amount paid per trip?\n",
    "spark.sql('''\n",
    "SELECT \n",
    "    YEAR(pickup_datetime) year, \n",
    "    MONTH(pickup_datetime) month,\n",
    "    ROUND((SUM(total_amount)/COUNT(*)), 2) avg_amount_per_trip\n",
    "FROM nyc_view\n",
    "GROUP BY YEAR(pickup_datetime), MONTH(pickup_datetime)\n",
    "ORDER BY 1,2\n",
    "''').show(24)\n",
    "#9:25 - 9:26 when using the saved cleand data in PQ format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------------------------+\n",
      "|year|month|avg_amount_paid_by_passenger|\n",
      "+----+-----+----------------------------+\n",
      "|2017|    1|                        9.78|\n",
      "|2017|    2|                        9.82|\n",
      "|2017|    3|                        9.95|\n",
      "|2017|    4|                        9.87|\n",
      "|2017|    5|                         9.9|\n",
      "|2017|    6|                        9.82|\n",
      "|2017|    7|                        9.87|\n",
      "|2017|    8|                         9.9|\n",
      "|2017|    9|                        9.91|\n",
      "|2017|   10|                        9.95|\n",
      "|2017|   11|                        9.94|\n",
      "|2017|   12|                        9.78|\n",
      "|2018|    1|                       10.05|\n",
      "|2018|    2|                       10.11|\n",
      "|2018|    3|                       10.07|\n",
      "|2018|    4|                       10.18|\n",
      "|2018|    5|                       10.26|\n",
      "|2018|    6|                       10.21|\n",
      "|2018|    7|                       10.19|\n",
      "|2018|    8|                       10.28|\n",
      "|2018|    9|                       10.39|\n",
      "|2018|   10|                       10.52|\n",
      "|2018|   11|                       10.43|\n",
      "|2018|   12|                       10.31|\n",
      "+----+-----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.a.vi What was the average amount paid per passenger?\n",
    "### http://spark.apache.org/docs/latest/sql-ref-functions-builtin.html\n",
    "spark.sql('''\n",
    "SELECT \n",
    "    YEAR(pickup_datetime) year, \n",
    "    MONTH(pickup_datetime) month,\n",
    "    ROUND((SUM(total_amount)/SUM(passenger_count)),2) avg_amount_paid_by_passenger\n",
    "FROM nyc_view\n",
    "GROUP BY YEAR(pickup_datetime), MONTH(pickup_datetime)\n",
    "ORDER BY 1,2\n",
    "''').show(24)\n",
    "#9:27 - 9:28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------------------+---------------------+------------------------+\n",
      "|taxi_campany|avg_trip_duation_sec|min_trip_duration_sec|max_trip_duration_sec|median_trip_duration_sec|\n",
      "+------------+--------------------+---------------------+---------------------+------------------------+\n",
      "|       Green|              727.62|                    1|                 1999|                     630|\n",
      "|      Yellow|              697.76|                    1|                 1999|                     593|\n",
      "+------------+--------------------+---------------------+---------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4.b.i For Each Taxi Color \n",
    "## What was the average, median, mini and max trip_duration in seconds\n",
    "\n",
    "spark.sql('''\n",
    "SELECT \n",
    "    taxi_campany,\n",
    "    ROUND(AVG(trip_duration_sec),2) avg_trip_duation_sec,\n",
    "    ROUND(MIN(trip_duration_sec),2) min_trip_duration_sec,\n",
    "    ROUND(MAX(trip_duration_sec),2) max_trip_duration_sec,\n",
    "    ROUND(APPROX_PERCENTILE(trip_duration_sec, 0.5),2) median_trip_duration_sec\n",
    "FROM nyc_view\n",
    "GROUP BY taxi_campany\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+----------------+----------------+-------------------+\n",
      "|taxi_campany|avg_trip_dist_km|min_trip_dist_km|max_trip_dist_km|median_trip_dist_km|\n",
      "+------------+----------------+----------------+----------------+-------------------+\n",
      "|       Green|            4.65|            1.61|           55.31|                2.0|\n",
      "|      Yellow|            4.89|            1.61|           52.95|               2.28|\n",
      "+------------+----------------+----------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Q-4.b.ii For Each Taxi Color What was the average, median, mini and max trip distance in Km\n",
    "spark.sql('''\n",
    "SELECT \n",
    "    taxi_campany,\n",
    "    ROUND((AVG(trip_distance)/0.621371),2) avg_trip_dist_km,\n",
    "    ROUND((MIN(trip_distance)/0.621371),2) min_trip_dist_km,\n",
    "    ROUND((MAX(trip_distance)/0.621371),2) max_trip_dist_km,\n",
    "    ROUND((APPROX_PERCENTILE(trip_distance, 0.5)),2) median_trip_dist_km\n",
    "FROM nyc_view\n",
    "GROUP BY taxi_campany\n",
    "''').show()\n",
    "# 9:30 - 9:31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+---------------+---------------+------------------+\n",
      "|taxi_campany|avg_speed_km_hr|min_speed_km_hr|max_speed_km_hr|median_speed_km_hr|\n",
      "+------------+---------------+---------------+---------------+------------------+\n",
      "|       Green|          18.99|            2.9|          99.99|              16.7|\n",
      "|      Yellow|           20.6|           2.91|           99.9|             18.51|\n",
      "+------------+---------------+---------------+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #### Q-4.b.iii For Each Taxi Color What was the average, median, mini and max speed in Km per hour\n",
    "# speed_km_hr\n",
    "spark.sql('''\n",
    "SELECT \n",
    "    taxi_campany,\n",
    "    ROUND(AVG(speed_km_hr),2) avg_speed_km_hr,\n",
    "    ROUND(MIN(speed_km_hr),2) min_speed_km_hr,\n",
    "    ROUND(MAX(speed_km_hr),2) max_speed_km_hr,\n",
    "    APPROX_PERCENTILE(speed_km_hr, 0.5) median_speed_km_hr\n",
    "FROM nyc_view\n",
    "GROUP BY taxi_campany\n",
    "''').show()\n",
    "#9:35 - 9:36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|trip_percent_with_tips|\n",
      "+----------------------+\n",
      "|                 61.83|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Q-4.c What was the percentage of trips where the driver received tips?\n",
    "spark.sql('''\n",
    "SET tipped_trip_count = (SELECT COUNT(*) tipped_trip_count\n",
    "FROM nyc_view\n",
    "WHERE tip_amount > 0)                           \n",
    "''')\n",
    "\n",
    "spark.sql('''\n",
    "SELECT ROUND((${tipped_trip_count}/COUNT(*)) * 100, 2) trip_percent_with_tips\n",
    "FROM nyc_view\n",
    "''').show()\n",
    "# 9:37 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|trip_percent_with_morethan_10dollars_tips|\n",
      "+-----------------------------------------+\n",
      "|                                     2.26|\n",
      "+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Q-4.d What was the percentage of trips where the driver received tips >= 10$ ?\n",
    "# https://www.javaer101.com/en/article/41891788.html ref for variable\n",
    "spark.sql('''\n",
    "SET high_tip_trip_count = (SELECT COUNT(*) high_tip_trip_count\n",
    "FROM nyc_view\n",
    "WHERE tip_amount >= 10)                           \n",
    "''')\n",
    "\n",
    "spark.sql('''\n",
    "SELECT ROUND((${high_tip_trip_count}/COUNT(*)) * 100, 2) trip_percent_with_morethan_10dollars_tips\n",
    "FROM nyc_view\n",
    "''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+\n",
      "|trip_duration_range_mins|average_speed_km_per_hr|\n",
      "+------------------------+-----------------------+\n",
      "|              10-20 mins|                  17.91|\n",
      "|               5-10 mins|                  19.27|\n",
      "|              20-30 mins|                  20.72|\n",
      "|                 <5 mins|                  28.16|\n",
      "|                >30 mins|                  23.51|\n",
      "+------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Q.4.e.i For each bin of trip duration - what is the average speed (Km per hour) - speed_km_hr\n",
    "spark.sql('''\n",
    "SELECT trip_duration_range_mins, ROUND(SUM(speed_km_hr)/ COUNT(*),2) average_speed_km_per_hr\n",
    "FROM nyc_view\n",
    "GROUP BY trip_duration_range_mins\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+---------------+----------------------+\n",
      "|trip_duration_range_mins|total_distance|sum_fare_amount|avg_dist_km_per_dollar|\n",
      "+------------------------+--------------+---------------+----------------------+\n",
      "|              10-20 mins|3.6325974517E8|1.27872238223E9|                  0.28|\n",
      "|               5-10 mins|1.2740173054E8| 5.1183941346E8|                  0.25|\n",
      "|              20-30 mins|2.7642736134E8|  8.351790931E8|                  0.33|\n",
      "|                 <5 mins|  1.01388973E7|  4.116772026E7|                  0.25|\n",
      "|                >30 mins| 6.819661047E7| 1.9123135426E8|                  0.36|\n",
      "+------------------------+--------------+---------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Q.4.e.ii For each bin of trip duration - what is the average distance (dist per dollar)\n",
    "spark.sql('''\n",
    "SELECT trip_duration_range_mins,\n",
    "       ROUND((SUM(trip_distance)/0.621371),2) total_distance,\n",
    "       ROUND(SUM(total_amount), 2) sum_fare_amount,\n",
    "       ROUND(((SUM(trip_distance)/0.621371) /  SUM(total_amount)), 2) avg_dist_km_per_dollar\n",
    "       \n",
    "FROM nyc_view\n",
    "GROUP BY trip_duration_range_mins       \n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q.4.f Which duration bin will you advise a taxi driver to target to maximise his income?\n",
    "\n",
    "The taxi drivers are suggested to target the passenger pick up for short distance which would take about 5 minutes or within 5 to 10 minutes to maximise their income. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
